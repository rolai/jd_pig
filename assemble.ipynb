{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入依赖库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assemble the pretrain model features, to trian a new network \n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import autograd\n",
    "from mxnet import gluon\n",
    "from mxnet import init\n",
    "from mxnet import nd\n",
    "from mxnet.gluon import nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "ctx = mx.gpu(2)\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义网络结构和评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    net = nn.Sequential()\n",
    "    with net.name_scope():\n",
    "        net.add(nn.BatchNorm())\n",
    "        net.add(nn.Dense(4096))\n",
    "        net.add(nn.BatchNorm())\n",
    "        net.add(nn.Activation('relu'))\n",
    "        net.add(nn.Dropout(0.5))\n",
    "        net.add(nn.Dense(1024))\n",
    "        net.add(nn.BatchNorm())\n",
    "        net.add(nn.Activation('relu'))\n",
    "        net.add(nn.Dropout(0.5))\n",
    "        net.add(nn.Dense(30))\n",
    "\n",
    "    net.initialize(ctx=ctx)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "def accuracy(output, labels):\n",
    "    return nd.mean(nd.argmax(output, axis=1) == labels).asscalar()\n",
    "\n",
    "def evaluate(net, data_iter):\n",
    "    loss, acc, n = 0., 0., 0.\n",
    "    steps = len(data_iter)\n",
    "    for data, label in data_iter:\n",
    "        data, label = data.as_in_context(ctx), label.as_in_context(ctx)\n",
    "        output = net(data)\n",
    "        acc += accuracy(output, label)\n",
    "        loss += nd.mean(softmax_cross_entropy(output, label)).asscalar()\n",
    "    return loss/steps, acc/steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入DenseNet和Inception-resnet-v2提取的feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17648, 5952)\n"
     ]
    }
   ],
   "source": [
    "# load train data\n",
    "\n",
    "feature_densenet = np.load('features/densenet/train_features.npy')\n",
    "feature_densenet_head = np.load('features/densenet-head/train_features.npy')\n",
    "feature_inception_res_v2 = np.load('features/inception_res_v2/train_features.npy')\n",
    "\n",
    "y = nd.load('jd_train_labels.nd')[0]\n",
    "y = y - 1\n",
    "\n",
    "features = nd.concat(\n",
    "                     nd.array(feature_densenet),\n",
    "                     nd.array(feature_densenet_head),\n",
    "                     nd.array(feature_inception_res_v2), dim=1)\n",
    "print(features.shape)\n",
    "\n",
    "data_iter_train_all = gluon.data.DataLoader(gluon.data.ArrayDataset(features, y), batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 5952)\n"
     ]
    }
   ],
   "source": [
    "# load eval data\n",
    "\n",
    "feature_densenet_eval = np.load('features/densenet/eval_features.npy')\n",
    "feature_densenet_head_eval = np.load('features/densenet-head/eval_features.npy')\n",
    "feature_inception_res_v2_eval = np.load('features/inception_res_v2/eval_features.npy')\n",
    "\n",
    "yy = nd.load('jd_eval_labels.nd')[0]\n",
    "yy = yy - 1\n",
    "\n",
    "features_eval = nd.concat(\n",
    "                          nd.array(feature_densenet_eval),\n",
    "                          nd.array(feature_densenet_head_eval),\n",
    "                          nd.array(feature_inception_res_v2_eval), dim=1)\n",
    "print(features_eval.shape)\n",
    "\n",
    "data_iter_eval = gluon.data.DataLoader(gluon.data.ArrayDataset(features_eval, yy), 128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 把高置信度的测试图片加入训练集（第一次训练时不要使用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20053, 5952)\n",
      "(20053,)\n"
     ]
    }
   ],
   "source": [
    "# combin the seleceted test images into train images\n",
    "\n",
    "features_all = nd.concat(\n",
    "                     features,\n",
    "                     nd.array(high_score_test_images), dim=0)\n",
    "y_all = nd.concat(y, nd.array(high_score_test_image_labels), dim=0)\n",
    "    \n",
    "print(features_all.shape)\n",
    "print(y_all.shape)\n",
    "\n",
    "data_iter_train_all = gluon.data.DataLoader(gluon.data.ArrayDataset(features_all, y_all), batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型并保存eval loss最小的最佳模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. loss: 0.1176, acc: 97.57%, eval_loss: 0.3660, eval_acc: 91.59%\n",
      "Epoch 2. loss: 0.0029, acc: 100.00%, eval_loss: 0.3905, eval_acc: 91.59%\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "\n",
    "net = build_model()\n",
    "\n",
    "epochs = 30\n",
    "lr_sch = mx.lr_scheduler.FactorScheduler(step=1000, factor=0.5, stop_factor_lr=1e-8)\n",
    "trainer = gluon.Trainer(net.collect_params(), 'adam', \n",
    "                        {'learning_rate': 4e-4, 'lr_scheduler': lr_sch, 'wd': 0.0})\n",
    "\n",
    "min_eval_loss = 0.4\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    steps = len(data_iter_train_all)\n",
    "    for data, label in data_iter_train_all:\n",
    "        data, label = data.as_in_context(ctx), label.as_in_context(ctx)\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            loss = softmax_cross_entropy(output, label)\n",
    "\n",
    "        loss.backward()\n",
    "        trainer.step(batch_size)\n",
    "\n",
    "        train_loss += nd.mean(loss).asscalar()\n",
    "        train_acc += accuracy(output, label)\n",
    "\n",
    "    # eval in the eval dataset, keep the model parameters of the mimial eval loss model\n",
    "    eval_loss, eval_acc = evaluate(net, data_iter_eval)\n",
    "    if min_eval_loss > eval_loss:\n",
    "        min_eval_loss = eval_loss\n",
    "        net.save_params('min_eval_loss_net.params')\n",
    "    print(\"Epoch %d. loss: %.4f, acc: %.2f%%, eval_loss: %.4f, eval_acc: %.2f%%\" % (epoch+1, train_loss/steps, train_acc/steps*100, eval_loss, eval_acc*100))\n",
    "    \n",
    "print(\"Min eval loss: %.4f\" % min_eval_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 载入最佳模型并在验证集上评测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.35200187239825026, 0.92343750000000002)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the best model\n",
    "net = build_model()\n",
    "net.load_params('min_eval_loss_net.params', ctx)  \n",
    "\n",
    "# eval in the eval dataset\n",
    "evaluate(net, data_iter_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 5952)\n"
     ]
    }
   ],
   "source": [
    "# load test data\n",
    "\n",
    "feature_densenet_test_b = np.load('features/densenet/test_b_features.npy')\n",
    "feature_densenet_head_test_b = np.load('features/densenet-head/test_b_features.npy')\n",
    "feature_inception_res_v2_test_b = np.load('features/inception_res_v2/test_b_features.npy')\n",
    "\n",
    "features_test_b = nd.concat(\n",
    "    nd.array(feature_densenet_test_b), \n",
    "    nd.array(feature_densenet_head_test_b),\n",
    "    nd.array(feature_inception_res_v2_test_b), dim=1)\n",
    "print(features_test_b.shape)\n",
    "\n",
    "data_iter_test_b = gluon.data.DataLoader(features_test_b, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用模型标注测试集，选取置信度高的数据加入训练集重新训练（可迭代多次）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3600, 5952)\n"
     ]
    }
   ],
   "source": [
    "# combine eval and test dataset\n",
    "features_test_all = nd.concat(features_test_b, features_eval, dim=0)\n",
    "print(features_test_all.shape)\n",
    "\n",
    "data_iter_test_all = gluon.data.DataLoader(features_test_all, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select 2405 images\n"
     ]
    }
   ],
   "source": [
    "high_score_test_images = np.empty((0, features_test_all.shape[1]), float)\n",
    "high_score_test_image_labels = []\n",
    "score_thred_hold = 0.99\n",
    "\n",
    "outputs = np.empty((0,30), float)\n",
    "for data in data_iter_test_all:\n",
    "    output = nd.softmax(net(data.as_in_context(ctx))).asnumpy()\n",
    "    outputs = np.append(outputs, output, axis=0)\n",
    "    \n",
    "preds = np.argmax(outputs, axis=1)\n",
    "scores = np.max(outputs, axis=1)\n",
    "for i in range(len(outputs)):\n",
    "    if scores[i] > score_thred_hold:\n",
    "        high_score_test_images = np.append(high_score_test_images, \n",
    "                                           np.expand_dims(features_test_all[i].asnumpy(), axis=0), \n",
    "                                           axis=0)\n",
    "        high_score_test_image_labels.append(preds[i])\n",
    "        \n",
    "print(\"Select %d images\" % (len(high_score_test_image_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测测试集并保存结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = np.empty((0,30), float)\n",
    "for data in features_test_b:\n",
    "    output = nd.softmax(net(data.as_in_context(ctx))).asnumpy()\n",
    "    outputs = np.append(outputs, output, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 390325.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = []\n",
    "for i, file_name in tqdm(enumerate(glob('jd_test_B/*.JPG')), total=3000):\n",
    "    name = file_name.split('/')[1][:-4]\n",
    "    files.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the test result\n",
    "\n",
    "with open('assemble_min_loss.csv', u\"w+\") as f:\n",
    "    for i in range(len(outputs)):\n",
    "        for j in range(30):\n",
    "            str_row = '%s,%d,%.9f\\n' % (files[i], j+1, outputs[i, j])\n",
    "            f.write(str_row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
