{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入依赖库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assemble the pretrain model features, to trian a new network \n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import autograd\n",
    "from mxnet import gluon\n",
    "from mxnet import init\n",
    "from mxnet import nd\n",
    "from mxnet.gluon import nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "ctx = mx.gpu(2)\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义网络结构和评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    net = nn.Sequential()\n",
    "    with net.name_scope():\n",
    "        net.add(nn.BatchNorm())\n",
    "        net.add(nn.Dense(4096))\n",
    "        net.add(nn.BatchNorm())\n",
    "        net.add(nn.Activation('relu'))\n",
    "        net.add(nn.Dropout(0.5))\n",
    "        net.add(nn.Dense(1024))\n",
    "        net.add(nn.BatchNorm())\n",
    "        net.add(nn.Activation('relu'))\n",
    "        net.add(nn.Dropout(0.5))\n",
    "        net.add(nn.Dense(30))\n",
    "\n",
    "    net.initialize(ctx=ctx)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "def accuracy(output, labels):\n",
    "    return nd.mean(nd.argmax(output, axis=1) == labels).asscalar()\n",
    "\n",
    "def evaluate(net, data_iter):\n",
    "    loss, acc, n = 0., 0., 0.\n",
    "    steps = len(data_iter)\n",
    "    for data, label in data_iter:\n",
    "        data, label = data.as_in_context(ctx), label.as_in_context(ctx)\n",
    "        output = net(data)\n",
    "        acc += accuracy(output, label)\n",
    "        loss += nd.mean(softmax_cross_entropy(output, label)).asscalar()\n",
    "    return loss/steps, acc/steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入DenseNet和Inception-resnet-v2提取的feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17648, 5952)\n"
     ]
    }
   ],
   "source": [
    "# load train data\n",
    "\n",
    "feature_densenet = np.load('features/densenet/train_features.npy')\n",
    "feature_densenet_head = np.load('features/densenet-head/train_features.npy')\n",
    "feature_inception_res_v2 = np.load('features/inception_res_v2/train_features.npy')\n",
    "\n",
    "y = nd.load('jd_train_labels.nd')[0]\n",
    "y = y - 1\n",
    "\n",
    "features = nd.concat(\n",
    "                     nd.array(feature_densenet),\n",
    "                     nd.array(feature_densenet_head),\n",
    "                     nd.array(feature_inception_res_v2), dim=1)\n",
    "print(features.shape)\n",
    "\n",
    "data_iter_train_all = gluon.data.DataLoader(gluon.data.ArrayDataset(features, y), batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 5952)\n"
     ]
    }
   ],
   "source": [
    "# load eval data\n",
    "\n",
    "feature_densenet_eval = np.load('features/densenet/eval_features.npy')\n",
    "feature_densenet_head_eval = np.load('features/densenet-head/eval_features.npy')\n",
    "feature_inception_res_v2_eval = np.load('features/inception_res_v2/eval_features.npy')\n",
    "\n",
    "yy = nd.load('jd_eval_labels.nd')[0]\n",
    "yy = yy - 1\n",
    "\n",
    "features_eval = nd.concat(\n",
    "                          nd.array(feature_densenet_eval),\n",
    "                          nd.array(feature_densenet_head_eval),\n",
    "                          nd.array(feature_inception_res_v2_eval), dim=1)\n",
    "print(features_eval.shape)\n",
    "\n",
    "data_iter_eval = gluon.data.DataLoader(gluon.data.ArrayDataset(features_eval, yy), 128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 把高置信度的测试图片加入训练集（第一次训练时不要使用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19411, 5952)\n",
      "(19411,)\n"
     ]
    }
   ],
   "source": [
    "# combin the seleceted test images into train images\n",
    "\n",
    "features_all = nd.concat(\n",
    "                     features,\n",
    "                     nd.array(high_score_test_images), dim=0)\n",
    "y_all = nd.concat(y, nd.array(high_score_test_image_labels), dim=0)\n",
    "    \n",
    "print(features_all.shape)\n",
    "print(y_all.shape)\n",
    "\n",
    "data_iter_train_all = gluon.data.DataLoader(gluon.data.ArrayDataset(features_all, y_all), batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型并保存eval loss最小的最佳模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. loss: 0.1104, acc: 97.63%, eval_loss: 0.4026, eval_acc: 90.11%\n",
      "Epoch 2. loss: 0.0020, acc: 100.00%, eval_loss: 0.3916, eval_acc: 90.11%\n",
      "Epoch 3. loss: 0.0012, acc: 100.00%, eval_loss: 0.3771, eval_acc: 90.81%\n",
      "Epoch 4. loss: 0.0008, acc: 99.99%, eval_loss: 0.3966, eval_acc: 89.96%\n",
      "Epoch 5. loss: 0.0005, acc: 100.00%, eval_loss: 0.3796, eval_acc: 90.65%\n",
      "Epoch 6. loss: 0.0004, acc: 100.00%, eval_loss: 0.3793, eval_acc: 90.34%\n",
      "Epoch 7. loss: 0.0003, acc: 100.00%, eval_loss: 0.3883, eval_acc: 90.11%\n",
      "Epoch 8. loss: 0.0003, acc: 100.00%, eval_loss: 0.3842, eval_acc: 90.34%\n",
      "Epoch 9. loss: 0.0002, acc: 100.00%, eval_loss: 0.3799, eval_acc: 90.65%\n",
      "Epoch 10. loss: 0.0002, acc: 100.00%, eval_loss: 0.3850, eval_acc: 90.65%\n",
      "Epoch 11. loss: 0.0002, acc: 100.00%, eval_loss: 0.3840, eval_acc: 90.65%\n",
      "Epoch 12. loss: 0.0002, acc: 100.00%, eval_loss: 0.3831, eval_acc: 90.65%\n",
      "Epoch 13. loss: 0.0001, acc: 100.00%, eval_loss: 0.3863, eval_acc: 90.97%\n",
      "Epoch 14. loss: 0.0001, acc: 100.00%, eval_loss: 0.3872, eval_acc: 90.97%\n",
      "Epoch 15. loss: 0.0001, acc: 100.00%, eval_loss: 0.3872, eval_acc: 90.81%\n",
      "Epoch 16. loss: 0.0001, acc: 100.00%, eval_loss: 0.3846, eval_acc: 90.65%\n",
      "Epoch 17. loss: 0.0001, acc: 100.00%, eval_loss: 0.3915, eval_acc: 90.65%\n",
      "Epoch 18. loss: 0.0001, acc: 100.00%, eval_loss: 0.3933, eval_acc: 90.50%\n",
      "Epoch 19. loss: 0.0001, acc: 100.00%, eval_loss: 0.3830, eval_acc: 90.97%\n",
      "Epoch 20. loss: 0.0001, acc: 100.00%, eval_loss: 0.3932, eval_acc: 90.81%\n",
      "Min eval loss: 0.3450\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "\n",
    "net = build_model()\n",
    "\n",
    "epochs = 20\n",
    "lr_sch = mx.lr_scheduler.FactorScheduler(step=1000, factor=0.5)\n",
    "trainer = gluon.Trainer(net.collect_params(), 'adam', \n",
    "                        {'learning_rate': 4e-4, 'lr_scheduler': lr_sch, 'wd': 0.0})\n",
    "\n",
    "min_eval_loss = 0.345\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    steps = len(data_iter_train_all)\n",
    "    for data, label in data_iter_train_all:\n",
    "        data, label = data.as_in_context(ctx), label.as_in_context(ctx)\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            loss = softmax_cross_entropy(output, label)\n",
    "\n",
    "        loss.backward()\n",
    "        trainer.step(batch_size)\n",
    "\n",
    "        train_loss += nd.mean(loss).asscalar()\n",
    "        train_acc += accuracy(output, label)\n",
    "\n",
    "    # eval in the eval dataset, keep the model parameters of the mimial eval loss model\n",
    "    eval_loss, eval_acc = evaluate(net, data_iter_eval)\n",
    "    if min_eval_loss > eval_loss:\n",
    "        min_eval_loss = eval_loss\n",
    "        net.save_params('min_eval_loss_net.params')\n",
    "    print(\"Epoch %d. loss: %.4f, acc: %.2f%%, eval_loss: %.4f, eval_acc: %.2f%%\" % (epoch+1, train_loss/steps, train_acc/steps*100, eval_loss, eval_acc*100))\n",
    "    \n",
    "print(\"Min eval loss: %.4f\" % min_eval_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 载入最佳模型并在验证集上评测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.34763741195201875, 0.91903408765792849)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the best model\n",
    "net = build_model()\n",
    "net.load_params('min_eval_loss_net.params', ctx)  \n",
    "\n",
    "# eval in the eval dataset\n",
    "evaluate(net, data_iter_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 5952)\n"
     ]
    }
   ],
   "source": [
    "# load test_a data\n",
    "\n",
    "feature_densenet_test_a = np.load('features/densenet/test_features.npy')\n",
    "feature_densenet_head_test_a = np.load('features/densenet-head/test_features.npy')\n",
    "feature_inception_res_v2_test_a = np.load('features/inception_res_v2/test_features.npy')\n",
    "\n",
    "features_test_a = nd.concat(\n",
    "    nd.array(feature_densenet_test_a), \n",
    "    nd.array(feature_densenet_head_test_a),\n",
    "    nd.array(feature_inception_res_v2_test_a), dim=1)\n",
    "print(features_test_a.shape)\n",
    "\n",
    "data_iter_test_a = gluon.data.DataLoader(features_test_a, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 5952)\n"
     ]
    }
   ],
   "source": [
    "# load test_b data\n",
    "\n",
    "feature_densenet_test_b = np.load('features/densenet/test_b_features.npy')\n",
    "feature_densenet_head_test_b = np.load('features/densenet-head/test_b_features.npy')\n",
    "feature_inception_res_v2_test_b = np.load('features/inception_res_v2/test_b_features.npy')\n",
    "\n",
    "features_test_b = nd.concat(\n",
    "    nd.array(feature_densenet_test_b), \n",
    "    nd.array(feature_densenet_head_test_b),\n",
    "    nd.array(feature_inception_res_v2_test_b), dim=1)\n",
    "print(features_test_b.shape)\n",
    "\n",
    "data_iter_test_b = gluon.data.DataLoader(features_test_b, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用模型标注测试集，选取置信度高的数据加入训练集重新训练（可迭代多次）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 5952)\n"
     ]
    }
   ],
   "source": [
    "# combine eval and test dataset\n",
    "features_test_all = nd.concat(features_test_b, features_test_a, dim=0)\n",
    "print(features_test_all.shape)\n",
    "\n",
    "data_iter_test_all = gluon.data.DataLoader(features_test_all, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select 1763 images\n"
     ]
    }
   ],
   "source": [
    "high_score_test_images = []\n",
    "high_score_test_image_labels = []\n",
    "score_thred_hold = 0.999\n",
    "\n",
    "outputs = np.empty((0,30), float)\n",
    "for data in data_iter_test_all:\n",
    "    output = nd.softmax(net(data.as_in_context(ctx))).asnumpy()\n",
    "    outputs = np.append(outputs, output, axis=0)\n",
    "    \n",
    "preds = np.argmax(outputs, axis=1)\n",
    "scores = np.max(outputs, axis=1)\n",
    "for i in range(len(outputs)):\n",
    "    if scores[i] > score_thred_hold:\n",
    "        high_score_test_images.append(features_test_all[i].asnumpy())\n",
    "        high_score_test_image_labels.append(preds[i])\n",
    "        \n",
    "print(\"Select %d images\" % (len(high_score_test_image_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测测试集并保存结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = np.empty((0,30), float)\n",
    "for data in features_test_b:\n",
    "    output = nd.softmax(net(data.as_in_context(ctx))).asnumpy()\n",
    "    outputs = np.append(outputs, output, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 390325.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = []\n",
    "for i, file_name in tqdm(enumerate(glob('jd_test_B/*.JPG')), total=3000):\n",
    "    name = file_name.split('/')[1][:-4]\n",
    "    files.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the test result\n",
    "\n",
    "with open('assemble_min_loss.csv', u\"w+\") as f:\n",
    "    for i in range(len(outputs)):\n",
    "        for j in range(30):\n",
    "            str_row = '%s,%d,%.9f\\n' % (files[i], j+1, outputs[i, j])\n",
    "            f.write(str_row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
